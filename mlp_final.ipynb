{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import uti\n",
    "from uti_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/Documents/1003-ML/project/uti.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  HomeMatches['Full_GoalDif']= stats.loc[stats['Home_Indicator']==1,'Full_GoalDif']\n",
      "/Users/ice/Documents/1003-ML/project/uti.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  AwayMatches['Full_GoalDif']= stats.loc[stats['Home_Indicator']==0,'Full_GoalDif']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France13.csv\n",
      "France14.csv\n",
      "France15.csv\n",
      "France16.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/Documents/1003-ML/project/uti.py:172: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  stats.loc[team_data['Home_Indicator']==0,'A_ShotsOnTargetRates']= np.cumsum(np.array(AwayMatches['Away_Shots_on_Target'])/np.array(HomeMatches['Away_Shots']))/NumMatches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England12.csv\n",
      "England13.csv\n",
      "England14.csv\n",
      "England15.csv\n",
      "England16.csv\n",
      "Germany13.csv\n",
      "Germany14.csv\n",
      "Germany15.csv\n",
      "Germany16.csv\n",
      "Germany17.csv\n",
      "Italy12.csv\n",
      "Italy13.csv\n",
      "Italy14.csv\n",
      "Italy15.csv\n",
      "Italy16.csv\n",
      "Spain12.csv\n",
      "Spain13.csv\n",
      "Spain14.csv\n",
      "Spain15.csv\n",
      "Spain16.csv\n",
      "mean accuracy:\n",
      "0.534044444444\n",
      "mean score:\n",
      "1.05187774482\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "score = []\n",
    "for nation in range(5):\n",
    "    League = [\"France\",\"England\",\"Germany\",\"Italy\",\"Spain\"]\n",
    "    DataPath = League[nation]\n",
    "    os.chdir(DataPath)\n",
    "    league_datasets= os.listdir()\n",
    "    league_datasets = sorted(league_datasets)\n",
    "    \n",
    "    for year in range(5):\n",
    "        # get one specific year\n",
    "        data = pd.read_csv(league_datasets[year])\n",
    "        print(league_datasets[year])\n",
    "        \n",
    "        # No change\n",
    "        teams = data['HomeTeam'].unique()\n",
    "\n",
    "        Model_Inputs = pd.DataFrame(columns=['Team','Opponent','H_Scores_Ave','H_Shots','H_ShotsOnTargetRates',\n",
    "                                  'H_Goals','H_LossGoals','H_Corners','H_Winning_Prob',\n",
    "                                  'A_Scores_Ave','A_Shots','A_ShotsOnTargetRates',\n",
    "                                  'A_Goals','A_LossGoals','A_Corners','A_Winning_Prob',\n",
    "                                  'GoalDif'\n",
    "                                  ])\n",
    "\n",
    "        Model_Inputs['Team']=data['HomeTeam']\n",
    "        Model_Inputs['Opponent']=data['AwayTeam']\n",
    "        Model_Inputs['GoalDif']=data['FTHG']-data['FTAG']\n",
    "\n",
    "        Home_Features=['H_Scores_Ave','H_Shots','H_ShotsOnTargetRates',\n",
    "                                  'H_Goals','H_LossGoals','H_Corners','H_Winning_Prob']\n",
    "\n",
    "        Away_Features=['A_Scores_Ave','A_Shots','A_ShotsOnTargetRates',\n",
    "                                  'A_Goals','A_LossGoals','A_Corners','A_Winning_Prob']\n",
    "\n",
    "        for t in teams:\n",
    "\n",
    "            team_data = uti.MatchResults(data,t)\n",
    "            t_stats = uti.Team_Stats(team_data)\n",
    "    \n",
    "            # Home Team \n",
    "            Model_Inputs.loc[Model_Inputs['Team']==t,Home_Features]=np.copy(t_stats[t_stats['Home_Indicator']==1].iloc[:,2:9])\n",
    "    \n",
    "            # Away Team\n",
    "            Model_Inputs.loc[Model_Inputs['Opponent']==t,Away_Features]=np.copy(t_stats[t_stats['Home_Indicator']==0].iloc[:,9:16])\n",
    "        \n",
    "        # create result result of [0 1 2], label of [H D A] \n",
    "        result = []\n",
    "        label = []\n",
    "        for i in range(Model_Inputs.shape[0]):\n",
    "            if Model_Inputs.iloc[i,-1] > 0:\n",
    "                result.append(1)\n",
    "                label.append('H')\n",
    "            elif Model_Inputs.iloc[i,-1] == 0:\n",
    "                result.append(2)\n",
    "                label.append('D')\n",
    "            else:\n",
    "                result.append(0)\n",
    "                label.append('A')\n",
    "        \n",
    "        Model_Inputs['result'] = result\n",
    "        Model_Inputs['label'] = label\n",
    "        \n",
    "        # fill na, scale\n",
    "        Model_Inputs = Model_Inputs.replace(np.inf, np.nan).fillna(0)\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df = pd.DataFrame(min_max_scaler.fit_transform(Model_Inputs.drop(['Team','Opponent','result','label','GoalDif'],axis=1)))\n",
    "        df.columns = Model_Inputs.columns[2:-3]\n",
    "        df['result'] = Model_Inputs['result']\n",
    "        df['label'] = Model_Inputs['label']\n",
    "        \n",
    "        # split train & test\n",
    "        match_per_round = 9 if nation == 2 else 10\n",
    "        k = 5\n",
    "        X_train = df.iloc[:-match_per_round*k,:-2]\n",
    "        X_test = df.iloc[-match_per_round*k:,:-2]\n",
    "        y_train = df.iloc[:-match_per_round*k,-1]\n",
    "        y_test = df.iloc[-match_per_round*k:,-1]\n",
    "        \n",
    "        # train mlp\n",
    "        mlp.fit(X_train,y_train)\n",
    "        mlp_preds = mlp.predict_proba(X_test)\n",
    "        \n",
    "        accuracy.append(mlp.score(X_test,y_test))\n",
    "        score.append(np.mean(Brier_Score(list(y_test),mlp_preds[:,1],mlp_preds[:,2],mlp_preds[:,0])))\n",
    "        \n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print('mean accuracy:')\n",
    "print(np.mean(accuracy))\n",
    "print('mean score:')\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataTransformer(data,features):\n",
    "    \n",
    "    \"\"\"\n",
    "    param:\n",
    "        @data: DataFrame\n",
    "        @features: (list) the features need to be extracted from original dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    team_lst = np.unique(data['HomeTeam'].tolist() + data['AwayTeam'].tolist())\n",
    "    team_store = {team:0 for team in team_lst} \n",
    "    \n",
    "    for team in team_lst:\n",
    "        home_data = data[data['HomeTeam']==team]\n",
    "        col_name = home_data.columns.tolist()  \n",
    "        col_name.insert(col_name.index('AwayTeam')+1,'Home_Indicator')  \n",
    "        home_data = home_data.reindex(columns=col_name)  \n",
    "        home_data['Home_Indicator'] = 1\n",
    "        home_data = home_data.rename(columns={'HomeTeam': 'Team', 'AwayTeam': 'Opponent', \n",
    "                                             'FTHG' : 'Team_Full_Goals', 'FTAG': 'Opponent_Full_Goals',\n",
    "                                             'HTHG': 'Team_Half_Goals', 'HTAG': 'Opponent_Half_Goals',\n",
    "                                             'HST': 'Team_Shots_On_Target', 'AST': 'Opponent_Shots_On_Target',\n",
    "                                             'HS': 'Team_Shots', 'AS':'Opponent_Shots'})\n",
    "        home_data['Goals'] = home_data['Team_Full_Goals']\n",
    "        \n",
    "        away_data = data[data['AwayTeam']==team]\n",
    "        col_name_2 = away_data.columns.tolist()  \n",
    "        col_name_2.insert(col_name_2.index('AwayTeam')+1,'Home_Indicator')  \n",
    "        away_data = away_data.reindex(columns=col_name_2)  \n",
    "        away_data['Home_Indicator'] = 0\n",
    "        away_data = away_data.rename(columns={'HomeTeam': 'Opponent', 'AwayTeam': 'Team', \n",
    "                                             'FTHG' : 'Opponent_Full_Goals', 'FTAG': 'Team_Full_Goals',\n",
    "                                             'HTHG': 'Opponent_Half_Goals', 'HTAG': 'Team_Half_Goals',\n",
    "                                             'HST': 'Opponent_Shots_On_Target', 'AST': 'Team_Shots_On_Target',\n",
    "                                             'HS': 'Opponent_Shots', 'AS':'Team_Shots'})\n",
    "        away_data['Goals'] = away_data['Opponent_Full_Goals']\n",
    "        \n",
    "        concat_data = pd.concat([home_data, away_data])\n",
    "        team_data = concat_data[features]\n",
    "        \n",
    "#         rename_dict = {'FTHG':'Full_Home_Goals','FTAG':'Full_Away_Goals','FTR':'Full_Results','HTHG':'Half_Home_Goals','HTAG':'Half_Away_Goals',\n",
    "#                        'HST':'Home_Shots_on_Target','AST':'Away_Shots_on_Target','AS':'Away_Shots','HS':'Home_Shots'}\n",
    "        rename_dict = {'FTR':'Full_Results'}\n",
    "        team_data = team_data.rename(columns=rename_dict)\n",
    "        \n",
    "        team_data['Date'] = [datetime.strptime(x, '%d/%m/%y') for x in team_data['Date']]\n",
    "        team_data = team_data.sort_values(by='Date')\n",
    "        \n",
    "        #compute the standing until the last game\n",
    "        col_name_3 = team_data.columns.tolist()  \n",
    "        col_name_3.insert(col_name_3.index('Full_Results')+1,'Standing')  \n",
    "        team_data = team_data.reindex(columns=col_name_3)\n",
    "\n",
    "        tmp = []      \n",
    "        for pair in zip(team_data['Home_Indicator'], team_data['Full_Results']):\n",
    "            if (pair[0]==0 and pair[1]=='A') or (pair[0]==1 and pair[1]=='H'):\n",
    "                tmp.append(3)\n",
    "            elif (pair[0]==1 and pair[1]=='A') or (pair[0]==0 and pair[1]=='H'):\n",
    "                tmp.append(0)\n",
    "            else:\n",
    "                tmp.append(1)\n",
    "\n",
    "        standing_lst = []\n",
    "        for i in range(len(tmp)+2):\n",
    "            if i > 1:\n",
    "                standing_lst.append(np.sum(tmp[:i-1]))\n",
    "\n",
    "        team_data['Standing'] = standing_lst\n",
    "        \n",
    "        #################################################################################\n",
    "        # goals, shots, shots_on_target last 2-5 games\n",
    "        for k in [5,4,3,2]:\n",
    "            col_name_4 = team_data.columns.tolist()  \n",
    "            col_name_4.insert(col_name_4.index('Team_Full_Goals')+1,'Team_Full_Goals_last'+str(k)+'_avg')\n",
    "            col_name_4.insert(col_name_4.index('Opponent_Full_Goals')+1,'Opponent_Full_Goals_last'+str(k)+'_avg')\n",
    "            col_name_4.insert(col_name_4.index('Team_Half_Goals')+1,'Team_Half_Goals_last'+str(k)+'_avg')\n",
    "            col_name_4.insert(col_name_4.index('Opponent_Half_Goals')+1,'Opponent_Half_Goals_last'+str(k)+'_avg')\n",
    "            col_name_4.insert(col_name_4.index('Team_Shots_On_Target')+1,'Team_Shots_On_Target_last'+str(k)+'_avg')\n",
    "            col_name_4.insert(col_name_4.index('Opponent_Shots_On_Target')+1,'Opponent_Shots_On_Target_last'+str(k)+'_avg')\n",
    "            team_data = team_data.reindex(columns=col_name_4)\n",
    "            fthg = []\n",
    "            ftag = []\n",
    "            hthg = []\n",
    "            htag = []\n",
    "            hst = []\n",
    "            ast = []\n",
    "            for i in range(len(tmp)):\n",
    "                if i - k + 1 < 0:\n",
    "                    fthg.append(np.sum(team_data['Team_Full_Goals'][0:i + 1])/ (i + 1))\n",
    "                    ftag.append(np.sum(team_data['Opponent_Full_Goals'][0:i + 1])/ (i + 1))\n",
    "                    hthg.append(np.sum(team_data['Team_Half_Goals'][0:i + 1])/ (i + 1))\n",
    "                    htag.append(np.sum(team_data['Opponent_Half_Goals'][0:i + 1])/ (i + 1))\n",
    "                    hst.append(np.sum(team_data['Team_Shots_On_Target'][0:i + 1])/ (i + 1))\n",
    "                    ast.append(np.sum(team_data['Opponent_Shots_On_Target'][0:i + 1])/ (i + 1))\n",
    "                else:   \n",
    "                    fthg.append(np.sum(team_data['Team_Full_Goals'][i - k + 1:i + 1])/k)\n",
    "                    ftag.append(np.sum(team_data['Opponent_Full_Goals'][i - k + 1:i + 1])/k)\n",
    "                    hthg.append(np.sum(team_data['Team_Half_Goals'][i - k + 1:i + 1])/k)\n",
    "                    htag.append(np.sum(team_data['Opponent_Half_Goals'][i - k + 1:i + 1])/k)\n",
    "                    hst.append(np.sum(team_data['Team_Shots_On_Target'][i - k + 1:i + 1])/k)\n",
    "                    ast.append(np.sum(team_data['Opponent_Shots_On_Target'][i - k + 1:i + 1])/k)\n",
    "            team_data['Team_Full_Goals_last'+str(k)+'_avg']= fthg\n",
    "            team_data['Opponent_Full_Goals_last'+str(k)+'_avg']= ftag\n",
    "            team_data['Team_Half_Goals_last'+str(k)+'_avg']= hthg\n",
    "            team_data['Opponent_Half_Goals_last'+str(k)+'_avg']= htag\n",
    "            team_data['Team_Shots_On_Target_last'+str(k)+'_avg']= hst\n",
    "            team_data['Opponent_Shots_On_Target_last'+str(k)+'_avg']= ast\n",
    "        #################################################################################\n",
    "        \n",
    "        #compute the winning probability\n",
    "        col_name_4 = team_data.columns.tolist()  \n",
    "        col_name_4.insert(col_name_4.index('Home_Indicator')+1,'Winning_Probability')\n",
    "        team_data = team_data.reindex(columns=col_name_4)\n",
    "        \n",
    "        col_name_4 = team_data.columns.tolist()\n",
    "        col_name_4.insert(col_name_4.index('Winning_Probability')+1,'Winning_Probability_last5')\n",
    "        team_data = team_data.reindex(columns=col_name_4)\n",
    "        \n",
    "        tmp_1 = []\n",
    "        for pair in zip(team_data['Home_Indicator'], team_data['Full_Results']):\n",
    "            if (pair[0]==0 and pair[1]=='A') or (pair[0]==1 and pair[1]=='H'):  #win\n",
    "                tmp_1.append(1)\n",
    "            elif (pair[0]==1 and pair[1]=='A') or (pair[0]==0 and pair[1]=='H'): #lose\n",
    "                tmp_1.append(0)\n",
    "            else: #draw\n",
    "                tmp_1.append(0)\n",
    "        \n",
    "        win_lst = []\n",
    "        win_last5 = []\n",
    "#         win_last5 = [0,0,0,0,0]\n",
    "        for i in range(len(tmp_1)):\n",
    "            win_lst.append(np.sum(tmp_1[:i + 1])/(i + 1))\n",
    "        for i in range(len(tmp_1)):\n",
    "            if i > 4:\n",
    "                win_last5.append(np.sum(tmp_1[i-4:i + 1])/5)\n",
    "            else:\n",
    "                win_last5.append(np.sum(tmp_1[0 : i + 1])/ (i + 1))\n",
    "        team_data['Winning_Probability']= win_lst\n",
    "        team_data['Winning_Probability_last5'] = win_last5\n",
    "        \n",
    "        #################################################################################\n",
    "        \n",
    "        #compute the winning probability of being home/away team\n",
    "        home_wprob_lst = []\n",
    "        away_wprob_lst = []\n",
    "        \n",
    "        for i in range(len(team_data)):\n",
    "            tmp_data = team_data[:i+1]\n",
    "            tmp_df = tmp_data[tmp_data['Home_Indicator']==1]\n",
    "            if len(tmp_df)==0:\n",
    "                home_wprob_lst.append(0)\n",
    "            else:\n",
    "                home_wprob = (len(tmp_df[tmp_df['Full_Results']=='H']))/len(tmp_df)\n",
    "                home_wprob_lst.append(home_wprob)\n",
    "\n",
    "            tmp_df1 = tmp_data[tmp_data['Home_Indicator']==0]\n",
    "            if len(tmp_df1)==0:\n",
    "                away_wprob_lst.append(0)\n",
    "            else:\n",
    "                away_wprob = (len(tmp_df1[tmp_df1['Full_Results']=='A']))/len(tmp_df1)\n",
    "                away_wprob_lst.append(away_wprob)\n",
    "        \n",
    "        col_name = team_data.columns.tolist() \n",
    "        col_name.insert(col_name.index('Winning_Probability_last5')+1,'Home_Win_Prob')\n",
    "        team_data = team_data.reindex(columns=col_name)\n",
    "        team_data['Home_Win_Prob'] = home_wprob_lst\n",
    "\n",
    "        col_name = team_data.columns.tolist() \n",
    "        col_name.insert(col_name.index('Home_Win_Prob')+1,'Away_Win_Prob')\n",
    "        team_data = team_data.reindex(columns=col_name)\n",
    "        team_data['Away_Win_Prob'] = away_wprob_lst\n",
    "        \n",
    "#         rename_dict = {'FTHG':'Full_Home_Goals','FTAG':'Full_Away_Goals','HTHG':'Half_Home_Goals','HTAG':'Half_Away_Goals',\n",
    "#                        'HST':'Home_Shots_on_Target','AST':'Away_Shots_on_Target','AS':'Away_Shots','HS':'Home_Shots'}\n",
    "        team_data = team_data.rename(columns=rename_dict)\n",
    "        \n",
    "        team_store[team] = team_data\n",
    "     \n",
    "    return team_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/Documents/1003-ML/project/uti_func.py:23: RuntimeWarning: invalid value encountered in true_divide\n",
      "  nor_probas = np.divide(1/odds,np.repeat(np.sum(probas,axis=1),3).values.reshape(n,3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France13.csv\n",
      "France14.csv\n",
      "France15.csv\n",
      "France16.csv\n",
      "England12.csv\n",
      "England13.csv\n",
      "England14.csv\n",
      "England15.csv\n",
      "England16.csv\n",
      "Germany13.csv\n",
      "Germany14.csv\n",
      "Germany15.csv\n",
      "Germany16.csv\n",
      "Germany17.csv\n",
      "Italy12.csv\n",
      "Italy13.csv\n",
      "Italy14.csv\n",
      "Italy15.csv\n",
      "Italy16.csv\n",
      "Spain12.csv\n",
      "Spain13.csv\n",
      "Spain14.csv\n",
      "Spain15.csv\n",
      "Spain16.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brier Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Probability L1 Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>0.678552</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.645550</td>\n",
       "      <td>0.361422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>0.713171</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.673412</td>\n",
       "      <td>0.401517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>0.675957</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.644909</td>\n",
       "      <td>0.340333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>0.699688</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.662436</td>\n",
       "      <td>0.410287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>0.683558</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.651618</td>\n",
       "      <td>0.454105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brier Score  Accuracy  Log Loss  Probability L1 Loss\n",
       "France      0.678552  0.332000  0.645550             0.361422\n",
       "England     0.713171  0.296000  0.673412             0.401517\n",
       "Germany     0.675957  0.377778  0.644909             0.340333\n",
       "Italy       0.699688  0.292000  0.662436             0.410287\n",
       "Spain       0.683558  0.376000  0.651618             0.454105"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_res =np.zeros((4,5))\n",
    "\n",
    "for nation in range(5):\n",
    "    League = [\"France\",\"England\",\"Germany\",\"Italy\",\"Spain\"]\n",
    "    DataPath = League[nation]\n",
    "    os.chdir(DataPath)\n",
    "    league_datasets= os.listdir()\n",
    "    league_datasets = sorted(league_datasets)\n",
    "    evaluation_matrices = np.zeros((4,len(league_datasets)))\n",
    "    \n",
    "    for year in range(5):\n",
    "        # get one specific year\n",
    "        data = pd.read_csv(league_datasets[year]).iloc[:,1:]\n",
    "        print(league_datasets[year])\n",
    "        \n",
    "        features_lst = ['Date','Team','Opponent', 'FTR', 'Home_Indicator','Team_Full_Goals', 'Opponent_Full_Goals',\n",
    "                        'Team_Half_Goals','Opponent_Half_Goals', 'Team_Shots_On_Target', 'Opponent_Shots_On_Target','Team_Shots','Opponent_Shots',\n",
    "                       'PSCH','PSCD','PSCA','Goals']\n",
    "        dict_ = dataTransformer(data, features_lst)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        i = 0\n",
    "        for k in dict_.keys():\n",
    "            i += 1\n",
    "            tmp = dict_[k]\n",
    "            a = tmp.iloc[:,:4].reset_index(drop = True)\n",
    "            init_row = pd.DataFrame(columns=tmp.columns[4:]).reset_index(drop=True)\n",
    "            init_row.loc[0] = [0]*len(tmp.columns[4:])\n",
    "            b = pd.concat([init_row,tmp.iloc[:-1,4:]]).reset_index(drop=True)\n",
    "            new = pd.concat([a, b],axis = 1)\n",
    "            df = pd.concat([df, new], axis = 0)  \n",
    "        # sort by date: split train and test by date!\n",
    "        df = df.sort_values(by=['Date']).reset_index(drop = True)\n",
    "        \n",
    "        # create result of [0 1 2]\n",
    "        df = df.loc[df['Full_Results'] != 0]\n",
    "        indicator = df[\"Home_Indicator\"].tolist()\n",
    "        result = df[\"Full_Results\"].tolist()\n",
    "        \n",
    "        # result: hometeam result\n",
    "        \n",
    "        # y: team result\n",
    "        # y_predict: team result\n",
    "        # y_result: team result\n",
    "        # 2 draw 1 team win 0 team lose\n",
    "        # D draw H team win A team lose\n",
    "        y = []\n",
    "        H = []\n",
    "        A = []\n",
    "        for i in range(len(result)):\n",
    "            if indicator[i] == 1:\n",
    "                H.append(df['PSCH'].tolist()[i])\n",
    "                A.append(df['PSCA'].tolist()[i])\n",
    "            else:\n",
    "                H.append(df['PSCA'].tolist()[i])\n",
    "                A.append(df['PSCH'].tolist()[i])\n",
    "        df['H'] = H\n",
    "        df['A'] = A   \n",
    "        \n",
    "        for i in range(len(result)):\n",
    "            if result[i] == 'D':\n",
    "                y.append(2)\n",
    "            elif indicator[i] == 1:\n",
    "                if result[i] == 'H':\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n",
    "            elif indicator[i] == 0:\n",
    "                if result[i] == 'A':\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n",
    "                    \n",
    "        # scale\n",
    "        df = df.replace(np.inf, np.nan).fillna(0)\n",
    "        X = df.iloc[:, 4:-6].as_matrix()\n",
    "        c_max = X.max(axis = 0)\n",
    "        c_min = X.min(axis = 0)\n",
    "        X = (X - c_min) / (c_max - c_min)\n",
    "        \n",
    "        # split train & test\n",
    "        match_per_round = 9 if nation == 2 else 10\n",
    "        k = 5\n",
    "        brier_score_mat = np.zeros((k,match_per_round))\n",
    "        accuracy_list = np.zeros((k))\n",
    "        cross_entropy_list = np.zeros((k))\n",
    "        probability_loss = np.zeros((k))\n",
    "        \n",
    "        # for each league and each year, loop last k runs\n",
    "        for j in range(k,0,-1): \n",
    "            # hold out the last m run as test data\n",
    "            X_train = X[:-match_per_round*j,:]\n",
    "            X_test = pd.DataFrame(X).tail(match_per_round*j)[:match_per_round]\n",
    "            y_train = y[:-match_per_round*j]\n",
    "            y_test = pd.DataFrame(y).tail(match_per_round*j)[:match_per_round]\n",
    "            \n",
    "            y_result = []\n",
    "            for i in range(len(y_test)):\n",
    "                if y_test[0].tolist()[i] == 1:\n",
    "                    y_result.append('H')\n",
    "                elif y_test[0].tolist()[i] == 0:\n",
    "                    y_result.append('D')\n",
    "                else:\n",
    "                    y_result.append('A')\n",
    "                    \n",
    "            # train mlp\n",
    "            mlp = MLPClassifier(solver='sgd',hidden_layer_sizes=(20,10),activation='relu', max_iter = 1000, shuffle = False)\n",
    "            mlp.fit(X_train,y_train)\n",
    "            mlp_preds = mlp.predict_proba(X_test) \n",
    "            \n",
    "            real_probability = odds_transfer(df[['H','PSCD','A']])\n",
    "            real_probability_mat =  real_probability.tail(match_per_round*j)[:match_per_round]\n",
    "            \n",
    "            # compute evaluation matric value for every road\n",
    "            brier_score_mat[k-j,] = Brier_Score(y_result,mlp_preds[:,1],mlp_preds[:,2],mlp_preds[:,0])\n",
    "            accuracy_list[k-j] = Accuracy(y_result,mlp_preds[:,1],mlp_preds[:,2],mlp_preds[:,0])\n",
    "            cross_entropy_list[k-j] = Cross_Entropy(y_result,mlp_preds[:,1],mlp_preds[:,2],mlp_preds[:,0])\n",
    "            probability_loss[k-j] = Probability_Difference(real_probability_mat,mlp_preds[:,1],mlp_preds[:,2],mlp_preds[:,0])\n",
    "\n",
    "        # Column year, row match round\n",
    "        evaluation_matrices[0,year]= np.mean(brier_score_mat)#sum(brier_score_mat.T)/matches_per_round\n",
    "        evaluation_matrices[1,year]= np.mean(accuracy_list)\n",
    "        evaluation_matrices[2,year]= np.mean(cross_entropy_list)\n",
    "        evaluation_matrices[3,year]= np.mean(probability_loss)\n",
    "        \n",
    "    os.chdir(\"../\")\n",
    "    league_res[:,nation] = np.mean(evaluation_matrices,axis=1)\n",
    "\n",
    "league_res.T\n",
    "pd.DataFrame(league_res.T,index=League,columns=['Brier Score','Accuracy','Log Loss','Probability L1 Loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(league_res.T,index=League,columns=['Brier Score','Accuracy','Log Loss','Probability L1 Loss']).to_csv(\"nn_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement: add opponent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one test, two teams, compare prob to win\n",
    "# p(a win) > = < p(b win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = dict()\n",
    "df1 = pd.DataFrame(columns=df.columns)\n",
    "df2 = pd.DataFrame(columns=df.columns)\n",
    "for i in range(df.shape[0]):\n",
    "    if (df.iloc[i,0],df.iloc[i,2],df.iloc[i,1]) in d:\n",
    "        df2 = df2.append(df.iloc[i])\n",
    "    else:\n",
    "        df1 = df1.append(df.iloc[i])\n",
    "        d[(df.iloc[i,0],df.iloc[i,1],df.iloc[i,2])] = 0\n",
    "\n",
    "df1 = df1.sort_values(['Date','Team']).reset_index(drop=True)\n",
    "df2 = df2.sort_values(['Date','Opponent']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/Documents/1003-ML/project/uti_func.py:23: RuntimeWarning: invalid value encountered in true_divide\n",
      "  nor_probas = np.divide(1/odds,np.repeat(np.sum(probas,axis=1),3).values.reshape(n,3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France13.csv\n",
      "France14.csv\n",
      "France15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France16.csv\n",
      "England12.csv\n",
      "England13.csv\n",
      "England14.csv\n",
      "England15.csv\n",
      "England16.csv\n",
      "Germany13.csv\n",
      "Germany14.csv\n",
      "Germany15.csv\n",
      "Germany16.csv\n",
      "Germany17.csv\n",
      "Italy12.csv\n",
      "Italy13.csv\n",
      "Italy14.csv\n",
      "Italy15.csv\n",
      "Italy16.csv\n",
      "Spain12.csv\n",
      "Spain13.csv\n",
      "Spain14.csv\n",
      "Spain15.csv\n",
      "Spain16.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brier Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Probability L1 Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>0.246376</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.344287</td>\n",
       "      <td>1.156317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>0.336276</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>1.133634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>0.267590</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.456501</td>\n",
       "      <td>1.176722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>0.329954</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.460893</td>\n",
       "      <td>1.173280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>0.103517</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.160942</td>\n",
       "      <td>1.226868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brier Score  Accuracy  Log Loss  Probability L1 Loss\n",
       "France      0.246376  0.840000  0.344287             1.156317\n",
       "England     0.336276  0.784000  0.496983             1.133634\n",
       "Germany     0.267590  0.835556  0.456501             1.176722\n",
       "Italy       0.329954  0.780000  0.460893             1.173280\n",
       "Spain       0.103517  0.948000  0.160942             1.226868"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_res =np.zeros((4,5))\n",
    "\n",
    "for nation in range(5):\n",
    "    League = [\"France\",\"England\",\"Germany\",\"Italy\",\"Spain\"]\n",
    "    DataPath = League[nation]\n",
    "    os.chdir(DataPath)\n",
    "    league_datasets= os.listdir()\n",
    "    league_datasets = sorted(league_datasets)\n",
    "    evaluation_matrices = np.zeros((4,len(league_datasets)))\n",
    "    \n",
    "    for year in range(5):\n",
    "        # get one specific year\n",
    "        data = pd.read_csv(league_datasets[year]).iloc[:,1:]\n",
    "        print(league_datasets[year])\n",
    "        \n",
    "        features_lst = ['Date','Team','Opponent', 'FTR', 'Home_Indicator','Team_Full_Goals', 'Opponent_Full_Goals',\n",
    "                        'Team_Half_Goals','Opponent_Half_Goals', 'Team_Shots_On_Target', 'Opponent_Shots_On_Target','Team_Shots','Opponent_Shots',\n",
    "                       'PSCH','PSCD','PSCA','Goals']\n",
    "        dict_ = dataTransformer(data, features_lst)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        i = 0\n",
    "        for k in dict_.keys():\n",
    "            i += 1\n",
    "            tmp = dict_[k]\n",
    "            a = tmp.iloc[:,:4].reset_index(drop = True)\n",
    "            tmp['Goals'] = tmp['Team_Full_Goals']\n",
    "            init_row = pd.DataFrame(columns=tmp.columns[4:]).reset_index(drop=True)\n",
    "            init_row.loc[0] = [0]*len(tmp.columns[4:])\n",
    "            b = pd.concat([init_row,tmp.iloc[:-1,4:]]).reset_index(drop=True)\n",
    "            new = pd.concat([a, b],axis = 1)\n",
    "            df = pd.concat([df, new], axis = 0)  \n",
    "        # sort by date: split train and test by date!\n",
    "        df = df.sort_values(by=['Date']).reset_index(drop = True)\n",
    "\n",
    "        # create result of [0 1 2]\n",
    "        df = df.loc[df['Full_Results'] != 0]\n",
    "        indicator = df[\"Home_Indicator\"].tolist()\n",
    "        result = df[\"Full_Results\"].tolist()\n",
    "\n",
    "        # result: hometeam result\n",
    "        \n",
    "        # y: team result\n",
    "        # y_predict: team result\n",
    "        # y_result: team result\n",
    "        # 2 draw 1 team win 0 team lose\n",
    "        # D draw H team win A team lose\n",
    "        H = []\n",
    "        A = []\n",
    "        for i in range(len(result)):\n",
    "            if indicator[i] == 1:\n",
    "                H.append(df['PSCH'].tolist()[i])\n",
    "                A.append(df['PSCA'].tolist()[i])\n",
    "            else:\n",
    "                H.append(df['PSCA'].tolist()[i])\n",
    "                A.append(df['PSCH'].tolist()[i])\n",
    "        df['H'] = H\n",
    "        df['A'] = A   \n",
    "        \n",
    "                    \n",
    "        # fill_na\n",
    "        df = df.replace(np.inf, np.nan).fillna(0)\n",
    "        \n",
    "        # split data of team and opponent\n",
    "        d = dict()\n",
    "        df1 = pd.DataFrame(columns=df.columns)\n",
    "        df2 = pd.DataFrame(columns=df.columns)\n",
    "        for i in range(df.shape[0]):\n",
    "            if (df.iloc[i,0],df.iloc[i,2],df.iloc[i,1]) in d:\n",
    "                df2 = df2.append(df.iloc[i])\n",
    "            else:\n",
    "                df1 = df1.append(df.iloc[i])\n",
    "                d[(df.iloc[i,0],df.iloc[i,1],df.iloc[i,2])] = 0\n",
    "\n",
    "        df1 = df1.sort_values(['Date','Team']).reset_index(drop=True)\n",
    "        df2 = df2.sort_values(['Date','Opponent']).reset_index(drop=True)\n",
    "        \n",
    "        # initial some parameter\n",
    "        match_per_round = 9 if nation == 2 else 10\n",
    "        k = 5\n",
    "        brier_score_mat = np.zeros((k,match_per_round))\n",
    "        accuracy_list = np.zeros((k))\n",
    "        cross_entropy_list = np.zeros((k))\n",
    "        probability_loss = np.zeros((k))\n",
    "        \n",
    "        # for each league and each year, loop last k runs\n",
    "        for j in range(k,0,-1):\n",
    "            \n",
    "            mlpr_preds_lst = []\n",
    "            result_lst = []\n",
    "            real_prob_lst = []\n",
    "            \n",
    "            for df in [df1,df2]:\n",
    "                # scale\n",
    "                X = df.iloc[:, 4:-6].as_matrix()\n",
    "                c_max = X.max(axis = 0)\n",
    "                c_min = X.min(axis = 0)\n",
    "                X = (X - c_min) / (c_max - c_min)\n",
    "                \n",
    "                y = df['Goals'].tolist()\n",
    "                \n",
    "                y_result = []\n",
    "                for i in range(len(y)):\n",
    "                    if y[i] == 1:\n",
    "                        y_result.append('H')\n",
    "                    elif y[i] == 0:\n",
    "                        y_result.append('D')\n",
    "                    else:\n",
    "                        y_result.append('A')\n",
    "                \n",
    "                # split train and test\n",
    "                X_train = X[:-match_per_round*j,:]\n",
    "                X_test = pd.DataFrame(X).tail(match_per_round*j)[:match_per_round]\n",
    "                y_train = y[:-match_per_round*j]\n",
    "                y_test = pd.DataFrame(y).tail(match_per_round*j)[:match_per_round]\n",
    "                y_test_result = pd.DataFrame(y_result).tail(match_per_round*j)[:match_per_round]\n",
    "                result_lst.append(y_test_result)\n",
    "                    \n",
    "                # train mlp for goals\n",
    "                mlpr = MLPRegressor(solver='sgd',hidden_layer_sizes=(20,10),activation='relu', max_iter = 1000, shuffle = False)\n",
    "                mlpr.fit(X_train,y_train)\n",
    "                mlpr_preds = mlpr.predict(X_test)\n",
    "                mlpr_preds_lst.append(mlpr_preds)\n",
    "            \n",
    "                real_probability = odds_transfer(df[['H','PSCD','A']])\n",
    "                real_probability_mat =  real_probability.tail(match_per_round*j)[:match_per_round]\n",
    "                real_prob_lst.append(real_probability_mat)\n",
    "            \n",
    "            # train mlp for probabilities of team in df2\n",
    "            mlpc = MLPClassifier(solver='sgd',hidden_layer_sizes=(20,10),activation='relu', max_iter = 1000, shuffle = False)\n",
    "            mlpc.fit(np.array([df1['Goals'].tolist(),df2['Goals'].tolist()]).T,y_result)\n",
    "            mlpc_preds = mlpc.predict_proba(np.array(mlpr_preds_lst).T)\n",
    "                \n",
    "            # compute evaluation matric value for every road\n",
    "            brier_score_mat[k-j,] = Brier_Score(y_test_result,mlpc_preds[:,2],mlpc_preds[:,1],mlpc_preds[:,0])\n",
    "            accuracy_list[k-j] = Accuracy(y_test_result,mlpc_preds[:,2],mlpc_preds[:,1],mlpc_preds[:,0])\n",
    "            cross_entropy_list[k-j] = Cross_Entropy(y_test_result,mlpc_preds[:,2],mlpc_preds[:,1],mlpc_preds[:,0])\n",
    "            probability_loss[k-j] = Probability_Difference(real_prob_lst[1],mlpc_preds[:,2],mlpc_preds[:,1],mlpc_preds[:,0])\n",
    "\n",
    "        # Column year, row match round\n",
    "        evaluation_matrices[0,year]= np.mean(brier_score_mat)#sum(brier_score_mat.T)/matches_per_round\n",
    "        evaluation_matrices[1,year]= np.mean(accuracy_list)\n",
    "        evaluation_matrices[2,year]= np.mean(cross_entropy_list)\n",
    "        evaluation_matrices[3,year]= np.mean(probability_loss)\n",
    "        \n",
    "    os.chdir(\"../\")\n",
    "    league_res[:,nation] = np.mean(evaluation_matrices,axis=1)\n",
    "\n",
    "league_res.T\n",
    "pd.DataFrame(league_res.T,index=League,columns=['Brier Score','Accuracy','Log Loss','Probability L1 Loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(league_res.T,index=League,columns=['Brier Score','Accuracy','Log Loss','Probability L1 Loss']).to_csv(\"nn_new_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
