{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter, OrderedDict\n",
    "import scipy.sparse as sp\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def prob_draw_lose(x):\n",
    "    if x > 1.5:\n",
    "        return 1\n",
    "    elif x < -1.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(x) / 3 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build lr on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 France12.csv\n",
      "1 France13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 France14.csv\n",
      "3 France15.csv\n",
      "4 France16.csv\n",
      "0 England12.csv\n",
      "1 England13.csv\n",
      "2 England14.csv\n",
      "3 England15.csv\n",
      "4 England16.csv\n",
      "0 Germany13.csv\n",
      "1 Germany14.csv\n",
      "2 Germany15.csv\n",
      "3 Germany16.csv\n",
      "4 Germany17.csv\n",
      "0 Italy12.csv\n",
      "1 Italy13.csv\n",
      "2 Italy14.csv\n",
      "3 Italy15.csv\n",
      "4 Italy16.csv\n",
      "0 Spain12.csv\n",
      "1 Spain13.csv\n",
      "2 Spain14.csv\n",
      "3 Spain15.csv\n",
      "4 Spain16.csv\n"
     ]
    }
   ],
   "source": [
    "#######lr on all datasets#######\n",
    "import baseline_only\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "import os\n",
    "import uti_func\n",
    "\n",
    "League = [\"France\",\"England\",\"Germany\",\"Italy\",\"Spain\"]\n",
    "league_res =np.zeros((4,5))\n",
    "\n",
    "# loop nation\n",
    "for n,nation in enumerate(League):\n",
    "    \n",
    "    # load data\n",
    "    DataPath = nation\n",
    "    \n",
    "    os.chdir(DataPath)\n",
    "    \n",
    "    league_datasets= os.listdir()\n",
    "    league_datasets = sorted(league_datasets)\n",
    "    \n",
    "    back_k_runs =5\n",
    "    \n",
    "    evaluation_matrices = np.zeros((4,len(league_datasets)))\n",
    "    \n",
    "    # For Germany League only, it is 9 matches per round\n",
    "    # For others, it is 10 matches per round\n",
    "    if nation !=\"Germany\":\n",
    "        matches_per_round = 10\n",
    "    else:\n",
    "        matches_per_round = 9\n",
    "    \n",
    "    total_rounds=2*(matches_per_round*2-1)\n",
    "    total_matches=2*(matches_per_round*2-1)*matches_per_round\n",
    "    \n",
    "    # loop year\n",
    "    for i,l in enumerate(league_datasets):\n",
    "        \n",
    "        print(i,l)\n",
    "        data = pd.read_csv(l)\n",
    "        \n",
    "        # data check\n",
    "        if len(data.iloc[:,1])!=total_matches:\n",
    "            print(\"the current dataset is: {}\".format(l))\n",
    "            print(\"human check required\")\n",
    "            break\n",
    "        \n",
    "        # load the features needed\n",
    "        inputs = data[['HomeTeam','AwayTeam','FTHG','FTAG']]\n",
    "        inputs['y'] = data['FTHG'] - data['FTAG']\n",
    "        inputs = inputs.rename(columns={'FTHG': 'HomeGoals', 'FTAG': 'AwayGoals'})   \n",
    "        \n",
    "        # create label\n",
    "        result = []\n",
    "        for r in range(inputs.shape[0]):\n",
    "            if inputs.iloc[r,-1] > 0:\n",
    "                result.append('H')\n",
    "            elif inputs.iloc[r,-1] == 0:\n",
    "                result.append('D')\n",
    "            else:\n",
    "                result.append('A')\n",
    "        inputs['label'] = result\n",
    "             \n",
    "        # transform data to indicator format\n",
    "        list_file = [(inputs['HomeTeam'][k], inputs['AwayTeam'][k]) for k in range(len(inputs['HomeTeam']))]\n",
    "        v = DictVectorizer()\n",
    "        # discover corpus and vectorize file word frequencies in a single pass\n",
    "        X = v.fit_transform(Counter(f) for f in list_file)\n",
    "        X = X.A\n",
    "        for ind in range(inputs.shape[0]):\n",
    "            X[i][v.vocabulary_[inputs['AwayTeam'][i]]] = -1;\n",
    "         \n",
    "        # initial evaluation matrics\n",
    "        brier_score_mat = np.zeros((back_k_runs,matches_per_round))\n",
    "        accuracy_list = np.zeros((back_k_runs))\n",
    "        cross_entropy_list = np.zeros((back_k_runs))\n",
    "        probability_loss = np.zeros((back_k_runs))\n",
    "        real_probability = uti_func.odds_transfer(data[['PSCH','PSCD','PSCA']])\n",
    "        \n",
    "        # for each league and each year, loop last k runs\n",
    "        for j in range(back_k_runs,0,-1): \n",
    "            # hold out the last m run as test data\n",
    "            X_train = X[:-matches_per_round*j,:]\n",
    "            X_test = pd.DataFrame(X).tail(matches_per_round*j)[:matches_per_round]\n",
    "            y_train = inputs['y'][:-matches_per_round*j]\n",
    "            y_test = inputs['label'].tail(matches_per_round*j)[:matches_per_round]\n",
    "            \n",
    "            # fit linear regression model with l2 regularization\n",
    "            reg = linear_model.Ridge(alpha =0.01)\n",
    "            reg.fit(X_train, y_train)\n",
    "            y_preds = reg.predict(X_test)\n",
    "            \n",
    "            # turn the diff prediction to three probabilities\n",
    "            y_probH = []\n",
    "            y_probD = []\n",
    "            y_probA = []\n",
    "            for pr in range(len(y_preds)):\n",
    "                y_probH.append(sigmoid(y_preds[pr]))\n",
    "                y_probD.append(prob_draw_lose(y_preds[pr])*(1-y_probH[pr]))\n",
    "                y_probA.append(1 - y_probH[pr] - y_probD[pr])\n",
    "\n",
    "            # compute evaluation matric value for every road\n",
    "            real_probability_mat =  real_probability.iloc[total_matches-matches_per_round*(back_k_runs-k):total_matches-matches_per_round*(back_k_runs-k-1),:]\n",
    "            brier_score_mat[back_k_runs-j,] = uti_func.Brier_Score(y_test, y_probH, y_probD, y_probA)\n",
    "            accuracy_list[back_k_runs-j] = uti_func.Accuracy(y_test, y_probH, y_probD, y_probA)\n",
    "            cross_entropy_list[back_k_runs-j] = uti_func.Cross_Entropy(y_test, y_probH, y_probD, y_probA)\n",
    "            probability_loss[back_k_runs-j] = uti_func.Probability_Difference(real_probability_mat, y_probH, y_probD, y_probA)\n",
    "\n",
    "        # Column year, row match round\n",
    "        evaluation_matrices[0,i]= np.mean (brier_score_mat)#sum(brier_score_mat.T)/matches_per_round\n",
    "        evaluation_matrices[1,i]= np.mean (accuracy_list)\n",
    "        evaluation_matrices[2,i]= np.mean (cross_entropy_list)\n",
    "        evaluation_matrices[3,i]= np.mean (probability_loss)\n",
    "        \n",
    "    \n",
    "        \n",
    "    os.chdir(\"../\")\n",
    "    league_res[:,n] = np.mean(evaluation_matrices,axis=1)\n",
    "\n",
    "league_res.T\n",
    "pd.DataFrame(league_res.T,index=League,columns=['brier_score','accuracy','cross-entropy','probability l1 loss']).to_csv(\"linear_reg_results.csv\")\n",
    "\n",
    "#rounds = range(total_rounds-back_k_runs+1,total_rounds+1)\n",
    "#plt.plot(rounds,brier_score_mat_league)\n",
    "#plt.ylabel('Median Brier Score per round')\n",
    "#plt.xlabel('Rounds')\n",
    "#plt.legend(('2012 - 2013', '2013 - 2014', '2014 - 2015','2015 - 2016','2016 - 2017'),\n",
    "#           loc='upper right')\n",
    "#\n",
    "#league_title = l[:-6] + \" Football League from 2012 -  2017\"\n",
    "#plt.title(league_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build mr on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 France12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 France13.csv\n",
      "2 France14.csv\n",
      "3 France15.csv\n",
      "4 France16.csv\n",
      "0 England12.csv\n",
      "1 England13.csv\n",
      "2 England14.csv\n",
      "3 England15.csv\n",
      "4 England16.csv\n",
      "0 Germany13.csv\n",
      "1 Germany14.csv\n",
      "2 Germany15.csv\n",
      "3 Germany16.csv\n",
      "4 Germany17.csv\n",
      "0 Italy12.csv\n",
      "1 Italy13.csv\n",
      "2 Italy14.csv\n",
      "3 Italy15.csv\n",
      "4 Italy16.csv\n",
      "0 Spain12.csv\n",
      "1 Spain13.csv\n",
      "2 Spain14.csv\n",
      "3 Spain15.csv\n",
      "4 Spain16.csv\n"
     ]
    }
   ],
   "source": [
    "# loop nation\n",
    "for n,nation in enumerate(League):\n",
    "    \n",
    "    # load data\n",
    "    DataPath = nation\n",
    "    \n",
    "    os.chdir(DataPath)\n",
    "    \n",
    "    league_datasets= os.listdir()\n",
    "    league_datasets = sorted(league_datasets)\n",
    "    \n",
    "    back_k_runs =5\n",
    "    \n",
    "    evaluation_matrices = np.zeros((4,len(league_datasets)))\n",
    "    \n",
    "    # For Germany League only, it is 9 matches per round\n",
    "    # For others, it is 10 matches per round\n",
    "    if nation !=\"Germany\":\n",
    "        matches_per_round = 10\n",
    "    else:\n",
    "        matches_per_round = 9\n",
    "    \n",
    "    total_rounds=2*(matches_per_round*2-1)\n",
    "    total_matches=2*(matches_per_round*2-1)*matches_per_round\n",
    "    \n",
    "    # loop year\n",
    "    for i,l in enumerate(league_datasets):\n",
    "        \n",
    "        print(i,l)\n",
    "        data = pd.read_csv(l)\n",
    "        \n",
    "        # data check\n",
    "        if len(data.iloc[:,1])!=total_matches:\n",
    "            print(\"the current dataset is: {}\".format(l))\n",
    "            print(\"human check required\")\n",
    "            break\n",
    "        \n",
    "        # load the features needed\n",
    "        inputs = data[['HomeTeam','AwayTeam','FTHG','FTAG']]\n",
    "        inputs['y'] = data['FTHG'] - data['FTAG']\n",
    "        inputs = inputs.rename(columns={'FTHG': 'HomeGoals', 'FTAG': 'AwayGoals'})   \n",
    "        \n",
    "        # create label\n",
    "        result = []\n",
    "        class_lst = []\n",
    "        for r in range(inputs.shape[0]):\n",
    "            if inputs.iloc[r,-1] > 0:\n",
    "                result.append('H')\n",
    "                class_lst.append(1)\n",
    "            elif inputs.iloc[r,-1] == 0:\n",
    "                result.append('D')\n",
    "                class_lst.append(0)\n",
    "            else:\n",
    "                result.append('A')\n",
    "                class_lst.append(2)\n",
    "        inputs['label'] = result\n",
    "        inputs['class'] = class_lst\n",
    "             \n",
    "        # transform data to indicator format\n",
    "        list_file = [(inputs['HomeTeam'][k], inputs['AwayTeam'][k]) for k in range(len(inputs['HomeTeam']))]\n",
    "        v = DictVectorizer()\n",
    "        # discover corpus and vectorize file word frequencies in a single pass\n",
    "        X = v.fit_transform(Counter(f) for f in list_file)\n",
    "        X = X.A\n",
    "        for ind in range(inputs.shape[0]):\n",
    "            X[i][v.vocabulary_[inputs['AwayTeam'][i]]] = -1;\n",
    "         \n",
    "        # initial evaluation matrics\n",
    "        brier_score_mat = np.zeros((back_k_runs,matches_per_round))\n",
    "        accuracy_list = np.zeros((back_k_runs))\n",
    "        cross_entropy_list = np.zeros((back_k_runs))\n",
    "        probability_loss = np.zeros((back_k_runs))\n",
    "        real_probability = uti_func.odds_transfer(data[['PSCH','PSCD','PSCA']])\n",
    "        \n",
    "        # for each league and each year, loop last k runs\n",
    "        for j in range(back_k_runs,0,-1): \n",
    "            # hold out the last m run as test data\n",
    "            X_train = X[:-matches_per_round*j,:]\n",
    "            X_test = pd.DataFrame(X).tail(matches_per_round*j)[:matches_per_round]\n",
    "            y_train = inputs['class'][:-matches_per_round*j]\n",
    "            y_test = inputs['label'].tail(matches_per_round*j)[:matches_per_round]\n",
    "            \n",
    "            # build multinomial logistic regression\n",
    "            mr = linear_model.LogisticRegression(tol=1e-10, max_iter=2000, solver='sag',multi_class='multinomial')\n",
    "            mr.fit(X_train,y_train)\n",
    "            y_preds_mr = mr.predict_proba(X_test)   \n",
    "\n",
    "            # compute evaluation matric value for every road\n",
    "            real_probability_mat =  real_probability.iloc[total_matches-matches_per_round*(back_k_runs-k):total_matches-matches_per_round*(back_k_runs-k-1),:]\n",
    "            brier_score_mat[back_k_runs-j,] = uti_func.Brier_Score(y_test, y_preds_mr[:,1], y_preds_mr[:,2], y_preds_mr[:,0])\n",
    "            accuracy_list[back_k_runs-j] = uti_func.Accuracy(y_test, y_preds_mr[:,1], y_preds_mr[:,2], y_preds_mr[:,0])\n",
    "            cross_entropy_list[back_k_runs-j] = uti_func.Cross_Entropy(y_test, y_preds_mr[:,1], y_preds_mr[:,2], y_preds_mr[:,0])\n",
    "            probability_loss[back_k_runs-j] = uti_func.Probability_Difference(real_probability_mat, y_preds_mr[:,1], y_preds_mr[:,2], y_preds_mr[:,0])\n",
    "\n",
    "        # Column year, row match round\n",
    "        evaluation_matrices[0,i]= np.mean (brier_score_mat)#sum(brier_score_mat.T)/matches_per_round\n",
    "        evaluation_matrices[1,i]= np.mean (accuracy_list)\n",
    "        evaluation_matrices[2,i]= np.mean (cross_entropy_list)\n",
    "        evaluation_matrices[3,i]= np.mean (probability_loss)\n",
    "        \n",
    "    \n",
    "        \n",
    "    os.chdir(\"../\")\n",
    "    league_res[:,n] = np.mean(evaluation_matrices,axis=1)\n",
    "\n",
    "league_res.T\n",
    "pd.DataFrame(league_res.T,index=League,columns=['brier_score','accuracy','cross-entropy','probability l1 loss']).to_csv(\"multi_log_results.csv\")\n",
    "\n",
    "#rounds = range(total_rounds-back_k_runs+1,total_rounds+1)\n",
    "#plt.plot(rounds,brier_score_mat_league)\n",
    "#plt.ylabel('Median Brier Score per round')\n",
    "#plt.xlabel('Rounds')\n",
    "#plt.legend(('2012 - 2013', '2013 - 2014', '2014 - 2015','2015 - 2016','2016 - 2017'),\n",
    "#           loc='upper right')\n",
    "#\n",
    "#league_title = l[:-6] + \" Football League from 2012 -  2017\"\n",
    "#plt.title(league_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
